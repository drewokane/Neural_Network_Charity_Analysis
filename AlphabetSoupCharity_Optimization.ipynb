{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 23:06:28.841770: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-14 23:06:28.842653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns=['EIN', 'NAME'])\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "T13         66\n",
       "Other       54\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "replace_application = application_df.APPLICATION_TYPE.value_counts()[application_df.APPLICATION_TYPE.value_counts() < 60].index\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ..?\n",
    "replace_class = application_df.CLASSIFICATION.value_counts()[application_df.CLASSIFICATION.value_counts() < 1000].index\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable lists\n",
    "application_cat = [k for k, v in application_df.dtypes.iteritems() if v == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhoslug/.cache/pypoetry/virtualenvs/trilogy-XBf8Ba-y-py3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T13  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  1.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T8  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                  0.0  ...                0.0                     0.0   \n",
       "1                  0.0  ...                1.0                     0.0   \n",
       "2                  0.0  ...                0.0                     0.0   \n",
       "3                  0.0  ...                0.0                     1.0   \n",
       "4                  0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df.loc[:, application_cat].values))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T13  APPLICATION_TYPE_T19  \\\n",
       "0                   1.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  1.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  0.0                  1.0  ...   \n",
       "3                  1.0                  0.0                  0.0  ...   \n",
       "4                  1.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "application_merged_df = application_df.merge(encode_df, left_index=True, right_index=True).drop(columns=application_cat)\n",
    "application_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_merged_df.IS_SUCCESSFUL.values\n",
    "X = application_merged_df.drop(columns=['IS_SUCCESSFUL']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 23:06:36.267241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-14 23:06:36.268171: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-14 23:06:36.269194: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-2ESRRKP): /proc/driver/nvidia/version does not exist\n",
      "2022-02-14 23:06:36.273114: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "nn_imported = tf.keras.models.load_model('AlphabetSoupCharity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 5s 5ms/step - loss: 0.5462 - accuracy: 0.7338\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5468 - accuracy: 0.7340\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5465 - accuracy: 0.7339\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5464 - accuracy: 0.7340\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7340\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5464 - accuracy: 0.7340\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5465 - accuracy: 0.7336\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7341\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7339\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7329\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7338\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5460 - accuracy: 0.7325\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7336\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5458 - accuracy: 0.7335\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7339\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7344\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7340\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7338\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7334\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7338\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7333\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7332\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7338\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7334\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7339\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7327\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7333\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7338\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7332\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7337\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7337\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7334\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7339\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7339\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7332\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7329\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5454 - accuracy: 0.7332\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7337\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7334\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7337\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7338\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7333\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7336\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7335\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7337\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7341\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7336\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7334\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7335\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7335\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5463 - accuracy: 0.7315\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7337\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7338\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7336\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7336\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7343\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7334\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7339\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5452 - accuracy: 0.7337\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7336\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7333\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7334\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5449 - accuracy: 0.7329\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7334\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7335\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7331\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7340\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7338\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 5s 7ms/step - loss: 0.5451 - accuracy: 0.7335\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7330\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7344\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7337\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7335\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7344\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5447 - accuracy: 0.7341\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5447 - accuracy: 0.7332\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7341\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5448 - accuracy: 0.7340\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5449 - accuracy: 0.7343\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7343\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7337\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5448 - accuracy: 0.7332\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5449 - accuracy: 0.7342\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5449 - accuracy: 0.7341\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5449 - accuracy: 0.7336\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5446 - accuracy: 0.7342\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5447 - accuracy: 0.7341\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5448 - accuracy: 0.7330\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5447 - accuracy: 0.7344\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5448 - accuracy: 0.7327\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5446 - accuracy: 0.7335\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5445 - accuracy: 0.7341\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5446 - accuracy: 0.7340\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5447 - accuracy: 0.7345\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7335\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5446 - accuracy: 0.7345\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7333\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5447 - accuracy: 0.7339\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5449 - accuracy: 0.7336\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaf1fe4280>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_imported.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5569 - accuracy: 0.7262 - 1s/epoch - 4ms/step\n",
      "Loss: 0.5568591952323914, Accuracy: 0.7261807322502136\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_imported.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f'Loss: {model_loss}, Accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the model (Adding nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6)                 276       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 393\n",
      "Trainable params: 393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = X.shape[1]\n",
    "hidden_layer_1_nodes = 6\n",
    "hidden_layer_2_nodes = 8\n",
    "hidden_layer_3_nodes = 6\n",
    "\n",
    "\n",
    "nn_big = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_big.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_1_nodes, input_dim=number_input_features, activation='relu')\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn_big.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_2_nodes, activation='relu')\n",
    ")\n",
    "\n",
    "nn_big.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_3_nodes, activation='relu')\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn_big.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_big.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_big.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 5s 5ms/step - loss: 0.6219 - accuracy: 0.6941\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5673 - accuracy: 0.7264\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5609 - accuracy: 0.7276\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5580 - accuracy: 0.7290\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5566 - accuracy: 0.7299\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5552 - accuracy: 0.7304\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5545 - accuracy: 0.7302\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5537 - accuracy: 0.7304\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5533 - accuracy: 0.7301\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5524 - accuracy: 0.7310\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5519 - accuracy: 0.7317\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5514 - accuracy: 0.7312\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5515 - accuracy: 0.7310\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5507 - accuracy: 0.7307\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5508 - accuracy: 0.7311\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5498 - accuracy: 0.7329\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5500 - accuracy: 0.7318\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5496 - accuracy: 0.7324\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5496 - accuracy: 0.7312\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5494 - accuracy: 0.7320\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5492 - accuracy: 0.7325\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5490 - accuracy: 0.7313\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5489 - accuracy: 0.7320\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5491 - accuracy: 0.7323\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5492 - accuracy: 0.7319\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5485 - accuracy: 0.7325\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5482 - accuracy: 0.7318\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5483 - accuracy: 0.7321\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5486 - accuracy: 0.7315\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5484 - accuracy: 0.7322\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5478 - accuracy: 0.7318\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5480 - accuracy: 0.7333\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5481 - accuracy: 0.7320\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5482 - accuracy: 0.7324\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5481 - accuracy: 0.7325\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5481 - accuracy: 0.7329\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5480 - accuracy: 0.7319\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5481 - accuracy: 0.7322\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5475 - accuracy: 0.7314\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5476 - accuracy: 0.7321\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5472 - accuracy: 0.7319\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5477 - accuracy: 0.7320\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5471 - accuracy: 0.7327\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5474 - accuracy: 0.7331\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5473 - accuracy: 0.7320\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5470 - accuracy: 0.7320\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5470 - accuracy: 0.7325\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5472 - accuracy: 0.7326\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5470 - accuracy: 0.7322\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5471 - accuracy: 0.7320\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5469 - accuracy: 0.7322\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5467 - accuracy: 0.7331\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5471 - accuracy: 0.7331\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5468 - accuracy: 0.7315\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5469 - accuracy: 0.7320\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5468 - accuracy: 0.7332\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5468 - accuracy: 0.7327\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5467 - accuracy: 0.7326\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5470 - accuracy: 0.7318\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5467 - accuracy: 0.7332\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5468 - accuracy: 0.7329\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5466 - accuracy: 0.7331\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5465 - accuracy: 0.7331\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5463 - accuracy: 0.7332\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7325\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5468 - accuracy: 0.7331\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5465 - accuracy: 0.7327\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5464 - accuracy: 0.7331\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5462 - accuracy: 0.7334\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5464 - accuracy: 0.7335\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5467 - accuracy: 0.7325\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5463 - accuracy: 0.7331\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7334\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5465 - accuracy: 0.7338\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5463 - accuracy: 0.7320\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5462 - accuracy: 0.7336\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5462 - accuracy: 0.7329\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7332\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5458 - accuracy: 0.7327\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5463 - accuracy: 0.7337\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7326\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7336\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7329\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7332\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5458 - accuracy: 0.7333\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7320\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7327\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7328\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5458 - accuracy: 0.7331\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5461 - accuracy: 0.7334\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7329\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7332\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5456 - accuracy: 0.7338\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7320\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7332\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7331\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7320\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7324\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7335\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5456 - accuracy: 0.7334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaf0aceaf0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_big.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:xlabel='STATUS', ylabel='STATUS'>,\n",
       "        <AxesSubplot:xlabel='ASK_AMT', ylabel='STATUS'>,\n",
       "        <AxesSubplot:xlabel='IS_SUCCESSFUL', ylabel='STATUS'>],\n",
       "       [<AxesSubplot:xlabel='STATUS', ylabel='ASK_AMT'>,\n",
       "        <AxesSubplot:xlabel='ASK_AMT', ylabel='ASK_AMT'>,\n",
       "        <AxesSubplot:xlabel='IS_SUCCESSFUL', ylabel='ASK_AMT'>],\n",
       "       [<AxesSubplot:xlabel='STATUS', ylabel='IS_SUCCESSFUL'>,\n",
       "        <AxesSubplot:xlabel='ASK_AMT', ylabel='IS_SUCCESSFUL'>,\n",
       "        <AxesSubplot:xlabel='IS_SUCCESSFUL', ylabel='IS_SUCCESSFUL'>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_matrix(application_df, figsize=(6, 6), diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the model (Munging data, altering neural net, activation function, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applications = pd.read_csv(\"charity_data.csv\")\n",
    "df_applications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications = df_applications.drop(columns=['EIN', 'NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_other = list(df_applications.CLASSIFICATION.value_counts()[df_applications.CLASSIFICATION.value_counts() < 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.loc[df_applications.CLASSIFICATION.isin(cls_other), 'CLASSIFICATION'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T9', 'T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_other = list(df_applications.APPLICATION_TYPE.value_counts()[df_applications.APPLICATION_TYPE.value_counts() < 500].index)\n",
    "app_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.loc[df_applications.APPLICATION_TYPE.isin(app_other), 'APPLICATION_TYPE'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                       0   \n",
       "1       1   108590              1                       0   \n",
       "2       1     5000              0                       0   \n",
       "3       1     6692              1                       0   \n",
       "4       1   142590              1                       0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                     1                     0                    0   \n",
       "1                     0                     0                    1   \n",
       "2                     0                     0                    0   \n",
       "3                     0                     0                    1   \n",
       "4                     0                     0                    1   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                    0                    0                    0  ...   \n",
       "1                    0                    0                    0  ...   \n",
       "2                    0                    1                    0  ...   \n",
       "3                    0                    0                    0  ...   \n",
       "4                    0                    0                    0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                  0                       0                         0   \n",
       "1                  1                       0                         0   \n",
       "2                  0                       0                         0   \n",
       "3                  0                       1                         0   \n",
       "4                  0                       0                         1   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                   0                 0                       0   \n",
       "1                   0                 0                       0   \n",
       "2                   0                 0                       0   \n",
       "3                   0                 0                       0   \n",
       "4                   0                 0                       0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                0                  0                         1   \n",
       "1                0                  0                         1   \n",
       "2                0                  0                         1   \n",
       "3                0                  0                         1   \n",
       "4                0                  0                         1   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applications_encoded = pd.get_dummies(df_applications)\n",
    "df_applications_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_applications_encoded.IS_SUCCESSFUL.values\n",
    "X = df_applications_encoded.drop(columns=['IS_SUCCESSFUL']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 6)                 300       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 28        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = X.shape[1]\n",
    "hidden_layer_1_nodes = 6\n",
    "hidden_layer_2_nodes = 4\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_1_nodes, input_dim=number_input_features, activation='tanh')\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_2_nodes, activation='tanh')\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 5s 5ms/step - loss: 0.6073 - accuracy: 0.6815\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5669 - accuracy: 0.7252\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5614 - accuracy: 0.7278\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5589 - accuracy: 0.7276\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5568 - accuracy: 0.7282\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5557 - accuracy: 0.7288\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5547 - accuracy: 0.7285\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5535 - accuracy: 0.7286\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5528 - accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5520 - accuracy: 0.7282\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5511 - accuracy: 0.7294\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5505 - accuracy: 0.7301\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5497 - accuracy: 0.7295\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5493 - accuracy: 0.7287\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5485 - accuracy: 0.7303\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5483 - accuracy: 0.7305\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5479 - accuracy: 0.7312\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5477 - accuracy: 0.7301\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5472 - accuracy: 0.7311\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5470 - accuracy: 0.7311\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5465 - accuracy: 0.7309\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5464 - accuracy: 0.7316\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5460 - accuracy: 0.7311\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5455 - accuracy: 0.7321\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7325\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5453 - accuracy: 0.7315\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7317\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5451 - accuracy: 0.7313\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7333\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7311\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5445 - accuracy: 0.7322\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5446 - accuracy: 0.7322\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5445 - accuracy: 0.7313\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5447 - accuracy: 0.7320\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5445 - accuracy: 0.7318\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5442 - accuracy: 0.7319\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5442 - accuracy: 0.7316\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5442 - accuracy: 0.7328\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5440 - accuracy: 0.7318\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5440 - accuracy: 0.7328\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5437 - accuracy: 0.7320\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5437 - accuracy: 0.7318\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5438 - accuracy: 0.7328\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5434 - accuracy: 0.7325\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5437 - accuracy: 0.7324\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5434 - accuracy: 0.7338\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5432 - accuracy: 0.7321\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5433 - accuracy: 0.7334\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5432 - accuracy: 0.7338\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5433 - accuracy: 0.7339\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5431 - accuracy: 0.7339\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5428 - accuracy: 0.7343\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5427 - accuracy: 0.7341\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5428 - accuracy: 0.7332\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5428 - accuracy: 0.7346\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5425 - accuracy: 0.7333\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5424 - accuracy: 0.7347\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5426 - accuracy: 0.7336\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5423 - accuracy: 0.7340\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5424 - accuracy: 0.7339\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5425 - accuracy: 0.7346\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5424 - accuracy: 0.7338\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7347\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5422 - accuracy: 0.7350\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5421 - accuracy: 0.7334\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7343\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7346\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5418 - accuracy: 0.7345\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7337\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5419 - accuracy: 0.7341\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5417 - accuracy: 0.7339\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7332\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5417 - accuracy: 0.7336\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5419 - accuracy: 0.7347\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7351\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5419 - accuracy: 0.7345\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5419 - accuracy: 0.7339\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5417 - accuracy: 0.7338\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5418 - accuracy: 0.7350\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5419 - accuracy: 0.7345\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5415 - accuracy: 0.7349\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5418 - accuracy: 0.7339\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7342\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5413 - accuracy: 0.7347\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7348\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5415 - accuracy: 0.7348\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5415 - accuracy: 0.7340\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5415 - accuracy: 0.7341\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5415 - accuracy: 0.7349\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5412 - accuracy: 0.7351\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5414 - accuracy: 0.7339\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5415 - accuracy: 0.7350\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5414 - accuracy: 0.7348\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5413 - accuracy: 0.7350\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5412 - accuracy: 0.7346\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5412 - accuracy: 0.7340\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5409 - accuracy: 0.7346\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5411 - accuracy: 0.7348\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5414 - accuracy: 0.7348\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5412 - accuracy: 0.7341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcafca41f10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5541 - accuracy: 0.7269 - 974ms/epoch - 4ms/step\n",
      "Loss: 0.5541114807128906, Accuracy: 0.7268804907798767\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f'Loss: {model_loss}, Accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 6)                 300       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 56        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417\n",
      "Trainable params: 417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = X.shape[1]\n",
    "hidden_layer_1_nodes = 6\n",
    "hidden_layer_2_nodes = 8\n",
    "hidden_layer_3_nodes = 6\n",
    "\n",
    "\n",
    "nn_big = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_big.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_1_nodes, input_dim=number_input_features, activation='tanh')\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn_big.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_2_nodes, activation='tanh')\n",
    ")\n",
    "\n",
    "nn_big.add(\n",
    "    tf.keras.layers.Dense(units=hidden_layer_3_nodes, activation='tanh')\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn_big.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_big.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_big.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "checkpoint_filename = 'checkpoints/optimized_weights.{epoch:02d}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 5s 5ms/step - loss: 0.5995 - accuracy: 0.6965\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5678 - accuracy: 0.7230\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5587 - accuracy: 0.7270\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5559 - accuracy: 0.7300\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5540 - accuracy: 0.7318\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5529 - accuracy: 0.7315\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5518 - accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5508 - accuracy: 0.7329\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5503 - accuracy: 0.7322\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5494 - accuracy: 0.7319\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5489 - accuracy: 0.7318\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5487 - accuracy: 0.7321\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5482 - accuracy: 0.7324\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5478 - accuracy: 0.7315\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5474 - accuracy: 0.7329\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5471 - accuracy: 0.7331\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5473 - accuracy: 0.7318\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5466 - accuracy: 0.7326\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5462 - accuracy: 0.7327\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5463 - accuracy: 0.7332\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5459 - accuracy: 0.7332\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5458 - accuracy: 0.7340\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5454 - accuracy: 0.7333\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5452 - accuracy: 0.7339\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5450 - accuracy: 0.7330\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5449 - accuracy: 0.7339\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5449 - accuracy: 0.7336\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5444 - accuracy: 0.7334\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5445 - accuracy: 0.7331\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5438 - accuracy: 0.7331\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5443 - accuracy: 0.7336\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5440 - accuracy: 0.7338\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5441 - accuracy: 0.7341\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5439 - accuracy: 0.7352\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5436 - accuracy: 0.7333\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5438 - accuracy: 0.7336\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5432 - accuracy: 0.7340\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5434 - accuracy: 0.7341\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5433 - accuracy: 0.7339\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5436 - accuracy: 0.7343\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5431 - accuracy: 0.7339\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5432 - accuracy: 0.7346\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5429 - accuracy: 0.7346\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5426 - accuracy: 0.7336\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5431 - accuracy: 0.7345\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5428 - accuracy: 0.7351\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5423 - accuracy: 0.7353\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5427 - accuracy: 0.7342\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5429 - accuracy: 0.7345\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5425 - accuracy: 0.7353\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5424 - accuracy: 0.7346\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5425 - accuracy: 0.7345\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5426 - accuracy: 0.7348\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5423 - accuracy: 0.7349\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5424 - accuracy: 0.7345\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7346\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5422 - accuracy: 0.7343\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5422 - accuracy: 0.7345\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7353\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5422 - accuracy: 0.7343\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5417 - accuracy: 0.7351\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5420 - accuracy: 0.7353\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5421 - accuracy: 0.7350\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5418 - accuracy: 0.7347\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5415 - accuracy: 0.7352\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5419 - accuracy: 0.7346\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5418 - accuracy: 0.7345\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5417 - accuracy: 0.7354\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7341\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7341\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5418 - accuracy: 0.7354\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7347\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5417 - accuracy: 0.7343\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7331\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7344\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5417 - accuracy: 0.7347\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5415 - accuracy: 0.7352\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7346\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5416 - accuracy: 0.7355\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5414 - accuracy: 0.7355\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5413 - accuracy: 0.7362\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5410 - accuracy: 0.7355\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 4s 6ms/step - loss: 0.5413 - accuracy: 0.7355\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5411 - accuracy: 0.7359\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5413 - accuracy: 0.7361\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5413 - accuracy: 0.7353\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5410 - accuracy: 0.7358\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5409 - accuracy: 0.7357\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5412 - accuracy: 0.7357\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5409 - accuracy: 0.7355\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5412 - accuracy: 0.7355\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5408 - accuracy: 0.7356\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5407 - accuracy: 0.7360\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5412 - accuracy: 0.7361\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5408 - accuracy: 0.7362\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5408 - accuracy: 0.7365\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5408 - accuracy: 0.7364\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5407 - accuracy: 0.7358\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5406 - accuracy: 0.7363\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5408 - accuracy: 0.7357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaee8909a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filename,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=804 * 5,    \n",
    ")\n",
    "nn_big.fit(X_train_scaled, y_train, epochs=100, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5543 - accuracy: 0.7258 - 954ms/epoch - 4ms/step\n",
      "Loss: 0.5542895197868347, Accuracy: 0.7258309125900269\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn_big.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f'Loss: {model_loss}, Accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_big.save('AlphabetSoupCharity_Optimization.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e321700b221a038dfa695be57a95375b2649d397f023be647cd0f8eeaf4c51ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('trilogy-XBf8Ba-y-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
